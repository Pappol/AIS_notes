{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# ELE510 Image Processing with robot vision: LAB, Exercise 6, Image features detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**Purpose:** *To learn about the edges and corners features detection, and their descriptors.*\n",
    "\n",
    "The theory for this exercise can be found in chapter 7 of the text book [1] and in appendix C in the compendium [2]. See also the following documentations for help:\n",
    "- [OpenCV](https://opencv.org/opencv-python-free-course/)\n",
    "- [numpy](https://numpy.org/doc/stable/)\n",
    "- [matplotlib](https://matplotlib.org/stable/contents.html)\n",
    "- [scipy](https://docs.scipy.org/doc/)\n",
    "\n",
    "\n",
    "**IMPORTANT:** Read the text carefully before starting the work. In\n",
    "many cases it is necessary to do some preparations before you start the work\n",
    "on the computer. Read necessary theory and answer the theoretical part\n",
    "first. The theoretical and experimental part should be solved individually.\n",
    "The notebook must be approved by the lecturer or his assistant.\n",
    "\n",
    "**Approval:**\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The current notebook should be submitted on CANVAS as a single pdf file. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    To export the notebook in a pdf format, goes to File -> Download as -> PDF via LaTeX (.pdf).\n",
    "</div>\n",
    "\n",
    "**Note regarding the notebook**: The theoretical questions can be answered directly on the notebook using a *Markdown* cell and LaTex commands (if relevant). In alternative, you can attach a scan (or an image) of the answer directly in the cell.\n",
    "\n",
    "Possible ways to insert an image in the markdown cell:\n",
    "\n",
    "`![image name](\"image_path\")`\n",
    "\n",
    "`<img src=\"image_path\" alt=\"Alt text\" title=\"Title text\" />`\n",
    "\n",
    "\n",
    "**Under you will find parts of the solution that is already programmed.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>You have to fill out code everywhere it is indicated with `...`</p>\n",
    "    <p>The code section under `######## a)` is answering subproblem a) etc.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "**Intensity edges** are pixels in the image where the intensity (or graylevel) function changes rapidly.\n",
    "\n",
    "The **Canny edge detector** is a classic algorithm for detecting intensity edges in a grayscale image that relies on the gradient magnitude. The algorithm was developed by John F. Canny in 1986. It is a multi-stage algorithm that provides good and reliable detection.\n",
    "\n",
    "**a)** Create the **Canny algorithm**, described at pag. 336 (alg. 7.1). For the last step (`EDGELINKING`) you can either use the algorithm 7.3 at page 338 or the `HYSTERESIS THRESHOLD` algorithm 10.3 described at page 451.\n",
    "All the following images are taken from the text book [1].\n",
    "\n",
    "![canny.png](images/canny.png)\n",
    "\n",
    "![nonmaxsuppression.png](images/nonmaxsuppression.png)\n",
    "\n",
    "![edgelinking.png](images/edgelinking.png)\n",
    "\n",
    "**Remember:**\n",
    "\n",
    "- Sigma (second parameter in the Canny algorithm) is not necessary for the calculation since the Sobel operator (in opencv) combines the Gaussian smoothing and differentiation, so the results is nore or less resistant to the noise. \n",
    "- We are defining the low and high thresholds manually in order to have a better comparison with the predefined opencv function. It is possible to extract the low and high thresholds automatically from the image but it is not required in this problem.\n",
    "\n",
    "**b)** Test your algorithm with a image of your choice and compare your results with the predefined function in opencv: \n",
    "\n",
    "```python\n",
    "cv2.Canny(img, t_low, t_high, L2gradient=True)\n",
    "``` \n",
    "[Documentation](https://docs.opencv.org/2.4/modules/imgproc/doc/feature_detection.html?highlight=canny#canny).\n",
    "\n",
    "### P.S. : \n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The goal of this problem it is not to create a **perfect** replication of the algorithm in opencv, but to understand the various steps involved and to be able to extract the edges from an ima ge using these steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel operator to find the first derivate in the horizontal and vertical directions\n",
    "def computeImageGradient(Im):\n",
    "    # Sobel operator  to find the first derivate in the horizontal and vertical directions\n",
    "    \n",
    "    ## TODO: The default ksize is 3, try different values and comment the result \n",
    "    g_x = cv2.Sobel(..., ddepth=cv2.CV_32F, ...)\n",
    "    g_y = cv2.Sobel(..., ddepth=cv2.CV_32F, ...)\n",
    "    \n",
    "    ############################\n",
    "    # Calculate the magnitude and the gradient direction like it is performed during the assignment 4 (problem 2a)\n",
    "    G_mag = ...\n",
    "    G_phase = ...\n",
    "        \n",
    "    return G_mag, G_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NonMaxSuppression algorithm \n",
    "def nonMaxSuppression(G_mag, G_phase):\n",
    "    G_localmax = np.zeros((G_mag.shape))\n",
    "    \n",
    "    # For each pixel, adjust the phase to ensure that -pi/8 <= theta < 7*pi/8\n",
    "    ...\n",
    "    \n",
    "    return G_localmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgeLinking(G_localmax, t_low, t_high):\n",
    "    I_edges = np.zeros((G_localmax.shape))\n",
    "    \n",
    "    # Set the threshold image and perform edge linking (or hysteresis thresholding)\n",
    "    ...\n",
    "    \n",
    "    return I_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that performs the Canny algorithm.\n",
    "\n",
    "The entire cell is locked, thus you can only test the function and NOT change it!\n",
    "\n",
    "Input: \n",
    "    - Im: image in grayscale\n",
    "    - t_low: first threshold for the hysteresis procedure (edge linking)\n",
    "    - t_high: second threshold for the hysteresis procedure (edge linking)\n",
    "\"\"\"\n",
    "def my_cannyAlgorithm(Im, t_low, t_high):\n",
    "    ## Compute the image gradient \n",
    "    G_mag, G_phase = computeImageGradient(Im)\n",
    "    \n",
    "    ## NonMaxSuppression algorithm \n",
    "    G_localmax = nonMaxSuppression(G_mag, G_phase)\n",
    "        \n",
    "    ## Edge linking\n",
    "    if t_low>t_high: t_low, t_high = t_high, t_low\n",
    "    I_edges = edgeLinking(G_localmax, t_low, t_high)\n",
    "    \n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.subplot(141), plt.imshow(G_mag, cmap='gray')\n",
    "    plt.title('Magnitude image.'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(142), plt.imshow(G_phase, cmap='gray')\n",
    "    plt.title('Phase image.'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(143), plt.imshow(G_localmax, cmap='gray')\n",
    "    plt.title('After non maximum suppression.'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(144), plt.imshow(I_edges, cmap='gray')\n",
    "    plt.title('Threshold image.'), plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    return I_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "Im = cv2.imread(..., cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "t_low = 100\n",
    "t_high = 250\n",
    "I_edges = my_cannyAlgorithm(Im, t_low, t_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# LOCKED cell: useful to check and visualize the results.\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.subplot(131), plt.imshow(Im, cmap='gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(I_edges, cmap='gray')\n",
    "plt.title('My Canny algorithm Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133), plt.imshow(cv2.Canny(Im,t_low, t_high, L2gradient=False), cmap='gray')\n",
    "plt.title('Canny algorithm Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Problem 2\n",
    "\n",
    "One of the most popular approaches to feature detection is the **Harris corner detector**, after a work of Chris Harris and Mike Stephens from 1988.\n",
    "\n",
    "**a)** Use the function in opencv `cv2.cornerHarris(...)` ([Documentation](https://docs.opencv.org/master/dd/d1a/group__imgproc__feature.html#gac1fc3598018010880e370e2f709b4345)) with `blockSize=3, ksize=3, k=0.04` with the **./images/chessboard.png** image to detect the corners (you can find the image on CANVAS).\n",
    "\n",
    "**b)** Plot the image with the detected corners found.\n",
    "\n",
    "**Hint**: Use the function `cv2.drawMarker(...)` ([Documentation](https://docs.opencv.org/4.5.3/d6/d6e/group__imgproc__draw.html#ga644c4a170d4799a56b29f864ce984b7e)) to show the corners in the image.\n",
    "\n",
    "**c)** Detect the corners using the images **./images/arrow_1.jpg**, **./images/arrow_2.jpg** and **./images/arrow_3.jpg**; describe and compare the results in the three images.\n",
    "\n",
    "**d)** What happen if you change (increase/decrease) the `k` constant for the \"corner points\"? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Problem 3 \n",
    "\n",
    "**a)** What is the SIFT approach? Describe the steps involved.\n",
    "\n",
    "**b)** Why this approach is more popular than the Harris detector?\n",
    "\n",
    "**c)** Explain the difference between a feature detector and a feature descriptor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers go here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Delivery (dead line) on CANVAS: 13.10.2023 at 23:59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Contact\n",
    "### Course teacher\n",
    "Professor Kjersti Engan, room E-431,\n",
    "E-mail: kjersti.engan@uis.no\n",
    "\n",
    "### Teaching assistant\n",
    "Saul Fuster Navarro, room E-401\n",
    "E-mail: saul.fusternavarro@uis.no\n",
    "\n",
    "\n",
    "Jorge Garcia Torres Fernandez, room E-401\n",
    "E-mail: jorge.garcia-torres@uis.no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## References\n",
    "\n",
    "[1] S. Birchfeld, Image Processing and Analysis. Cengage Learning, 2016.\n",
    "\n",
    "[2] I. Austvoll, \"Machine/robot vision part I,\" University of Stavanger, 2018. Compendium, CANVAS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
