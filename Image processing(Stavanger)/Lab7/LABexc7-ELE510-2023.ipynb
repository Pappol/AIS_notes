{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELE510 Image Processing with robot vision: LAB, Exercise 7, Stereo Vision and Camera Calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "**Purpose:** *To learn about imaging with two cameras, stereo, and reconstrution by triangulation.*\n",
    "\n",
    "The theory for this exercise can be found in chapter 13 of the text book [1] and in chapter 4 in the compendium [2]. \n",
    "See also the following documentations for help:\n",
    "- [OpenCV](https://docs.opencv.org/4.8.0/d6/d00/tutorial_py_root.html)\n",
    "- [numpy](https://numpy.org/doc/stable/)\n",
    "- [matplotlib](https://matplotlib.org/stable/users/index.html)\n",
    "- [scipy](https://docs.scipy.org/doc/)\n",
    "\n",
    "**IMPORTANT:** Read the text carefully before starting the work. In\n",
    "many cases it is necessary to do some preparations before you start the work\n",
    "on the computer. Read necessary theory and answer the theoretical part\n",
    "first. The theoretical and experimental part should be solved individually.\n",
    "The notebook must be approved by the lecturer or his assistant.\n",
    "\n",
    "**Approval:**\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "The current notebook should be submitted on CANVAS as a single pdf file. \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    To export the notebook in a pdf format, goes to File -> Download as -> PDF via LaTeX (.pdf).\n",
    "</div>\n",
    "\n",
    "**Note regarding the notebook**: The theoretical questions can be answered directly on the notebook using a *Markdown* cell and LaTex commands (if relevant). In alternative, you can attach a scan (or an image) of the answer directly in the cell.\n",
    "\n",
    "Possible ways to insert an image in the markdown cell:\n",
    "\n",
    "`![image name](\"image_path\")`\n",
    "\n",
    "`<img src=\"image_path\" alt=\"Alt text\" title=\"Title text\" />`\n",
    "\n",
    "\n",
    "**Under you will find parts of the solution that is already programmed.**\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>You have to fill out code everywhere it is indicated with `...`</p>\n",
    "    <p>The code section under `######## a)` is answering subproblem a) etc.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "## Problem 1 (Correspondence problem) \n",
    "\n",
    "![stereocamera.png](images/stereocamera.png)\n",
    "\n",
    "Assume that we have a simple stereo system as shown in the figure. **L** and **R** denotes the focal point of the Left and Right camera respectively.  ${\\mathbf P}$ is a point in the 3D world, and ${\\mathbf p}$ in the 2D image plane. $^{\\small L}{\\mathbf P_w}$ denotes a world point with reference to the focal point of the Left camera.  \n",
    "The baseline (line between the two optical centers) is $T = 5\\,\\text{cm}$ and the focal length $f = 5\\,\\text{cm}$. \n",
    "\n",
    "**a)** Consider the scene point $^{\\small L}{\\mathbf P_w} = [0.05\\text{m},0,10\\text{m}]^{T}$. Suppose that due to various errors, the image coordinate $x_{l}$ is 2% **bigger** than its true value, while the image coordinate $x_{r}$ is perfect. What is the error in depth $z_w$, in millimeters (round up to three decimals)?\n",
    "\n",
    "**b)** An image of resolution $500\\times500$ pixels is seen by the Left and Right cameras. The image sensor size is $10\\text{mm} \\times 10\\text{mm}$.  Let the disparity in the image coordinates be up to $25$ pixels. Using the same focal point and baseline, what is the depth of the image compare to the cameras?\n",
    "\n",
    "**c)** Can you explain with your own words the stereo ordering constraint? What is the definition of forbidden zone in this scenario?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Problem 2 (Block Matching)\n",
    "\n",
    "The simplest algorithm to compute dense correspondence between a pair of stereo images is **block matching**.\n",
    "Block matching is an *area-based* approach that relies upon a statistical correlation between local intensity regions.\n",
    "\n",
    "For each pixel (x,y) in the left image, the right image is searched for the best match among all possible disparities $0 \\le d \\le d_{\\text{max}}$.\n",
    "\n",
    "**a)** Use the function `cv2.StereoBM_create(numDisparities=0, blockSize=21)` ([Documentation](https://docs.opencv.org/master/d9/dba/classcv_1_1StereoBM.html)) \n",
    "([Class Documentation](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#stereobm))\n",
    "to computing stereo correspondence using the block matching algorithm. \n",
    "\n",
    "Find the disparity map between the following images: **./images/aloeL.jpg** and **./image/aloeR.jpg**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "\n",
    "**b)** What happens if you increase the `numDisparities` parameter in the `cv2.StereoBM_create()`? And if you change the `blockSize` parameter?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## Problem 3 (Camera calibration)\n",
    "\n",
    "Calibrate the camera using a set of checkerboard images (you can find them in *./images/left??.jpg*), where `??` indicates the index of the image \n",
    "\n",
    "<details style=\"margin-top:20px\">\n",
    "    <summary>\n",
    "        <font size=\"2\" color=\"green\"><b>Click here for an optional hint</b></font>\n",
    "    </summary>\n",
    "    </font>\n",
    "</summary>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Use the following lines to get the entire list of the images to process:\n",
    "    \n",
    "```python\n",
    "from glob import glob\n",
    "\n",
    "img_names = glob('./images/left??.jpg')\n",
    "```\n",
    "    \n",
    "</div>\n",
    "</details>\n",
    "\n",
    "\n",
    "**a)** Use the checkerboard images to find the feature points using the openCV `cv2.findChessboardCorners()` function ([Documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga93efa9b0aa890de240ca32b11253dd4a)).\n",
    "\n",
    "Normally, we have talked about camera calibration as a method to know the intrinsic parameters of the camera, here we want to use the camera matrix and the relative distortion coefficients to undistort the previous images.\n",
    "For a detailed explanation of distortion, read section 13.4.9 of the text book [1].\n",
    "\n",
    "**b)** Calibrate the camera using the feature points discovered in **a)** and find the relative camera matrix and distortion coefficients using `cv2.calibrateCamera()` function ([Documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga3207604e4b1a1758aa66acb6ed5aa65d)).\n",
    "\n",
    "**P.S.:**   \n",
    "By default, you should find 5 distortion coeffiencients (3 radial distortion coeff. ($k_1, k_2, k_3$) and 2 tangential coeff. ($p_1,p_2$)); these values are used later to find a new camera matrix and to undistort the images.    \n",
    "\n",
    "**c)** Using the camera matrix and distortion coefficients, transform the images to compensate any kind of distortion using \n",
    " `cv2.getOptimalNewCameraMatrix()` ([Documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html#ga7a6c4e032c97f03ba747966e6ad862b1)) and `cv2.undistort()` ([Documentation](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga69f2545a8b62a6b0fc2ee060dc30559d)).\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "# Function to find the feature points using cv2.findChessboardCorners(...)\n",
    "# If the function finds the corners, return them, otherwise return None  \n",
    "def findCorners(filename, pattern_size):\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    found, corners = cv2.findChessboardCorners(...)\n",
    "    \n",
    "    # ...\n",
    "    \n",
    "    if not found: return None\n",
    "    return corners.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to ellipsis here. Maybe you meant '==' instead of '='? (214385644.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    ... = cv2.calibrateCamera(..., cameraMatrix=None, distCoeffs=None)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to ellipsis here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "# Function to calibrate the camera.\n",
    "# Return the camera matrix and the distortion coeffiecients (radial & tangential)\n",
    "def calibrateTheCamera(obj_points, img_points, img_shape):\n",
    "    \n",
    "    # The function estimates the intrinsic camera parameters and extrinsic parameters for each of the views\n",
    "    ... = cv2.calibrateCamera(..., cameraMatrix=None, distCoeffs=None)\n",
    "    \n",
    "    \n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "# Function that undistort the images using cv2.getOptimalNewCameraMatrix(...) and cv2.undistort(...)\n",
    "# Plot the new undistorted images.\n",
    "def undistortImage(filename, camera_matrix, dist_coefs):\n",
    "    \n",
    "    img = cv2.imread(filename,0)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Returns the new camera intrinsic matrix based on the camera matrix and the distortion coefficients\n",
    "    ... = cv2.getOptimalNewCameraMatrix(...)\n",
    "    \n",
    "    # Transforms an image to compensate for lens distortion using the camera matrix, \n",
    "    # the distortion coefficients and the camera matrix of the distorted image.\n",
    "    ... = cv2.undistort(...)\n",
    "    \n",
    "    plt.figure(figsize=(30,30))\n",
    "    plt.imshow(...)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "obj_points = []\n",
    "img_points = []\n",
    "img_names = glob(...)\n",
    "\n",
    "\n",
    "# From the documentation of cv2.findChessboardCorners:\n",
    "# patternSize â€“ Number of inner corners per a chessboard row and column\n",
    "#( patternSize = cvSize(points_per_row,points_per_colum) = cvSize(columns,rows) ).\n",
    "pattern_size = (9,6)\n",
    "\n",
    "# Defining the world coordinates for 3D points\n",
    "pattern_points = np.zeros((np.prod(pattern_size), 3), np.float32)\n",
    "pattern_points[:, :2] = np.indices(pattern_size).T.reshape(-1, 2)\n",
    "pattern_points *= 1\n",
    "\n",
    "#### a)\n",
    "# Find feature points with checkerboard images.\n",
    "chessboards = [findCorners(filename, pattern_size) for filename in img_names]\n",
    "for corners in [chessboard for chessboard in chessboards if chessboard is not None]:\n",
    "    img_points.append(corners)\n",
    "    obj_points.append(pattern_points)\n",
    "\n",
    "#### b)\n",
    "# Get the camera matrix and the distortion coeffiecients (radial & tangential).\n",
    "img_shape = cv2.imread(img_names[0], cv2.IMREAD_GRAYSCALE).shape[:2]\n",
    "camera_matrix, dist_coefs = calibrateTheCamera(obj_points, img_points, img_shape)\n",
    "\n",
    "#### c) \n",
    "# Undistort the images and plot them.\n",
    "for filename in img_names:\n",
    "    undistortImage(filename, camera_matrix, dist_coefs)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "### Delivery (dead line) on CANVAS: 21.10.2022 at 23:59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "run_control": {
     "frozen": false
    }
   },
   "source": [
    "## Contact\n",
    "### Course teacher\n",
    "Professor Kjersti Engan, room E-431,\n",
    "E-mail: kjersti.engan@uis.no\n",
    "\n",
    "### Teaching assistant\n",
    "Saul Fuster Navarro, room E-401\n",
    "E-mail: saul.fusternavarro@uis.no\n",
    "\n",
    "\n",
    "Jorge Garcia Torres Fernandez, room E-401\n",
    "E-mail: jorge.garcia-torres@uis.no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "\n",
    "## References\n",
    "\n",
    "[1] S. Birchfeld, Image Processing and Analysis. Cengage Learning, 2016.\n",
    "\n",
    "[2] I. Austvoll, \"Machine/robot vision part I,\" University of Stavanger, 2018. Compendium, CANVAS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
